{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ccf45d6-0e33-41ac-97c7-f7cd32b2db3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cdac9d0f-894d-482c-b8f8-557409d5f2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load the Data\n",
    "file_path = '/Users/rohanpadaya/Desktop/pankit_assign/Stock_data_part1.csv'  \n",
    "stock_data_1 = pd.read_csv(file_path, low_memory=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe71ed22-7e37-456d-ba66-e11c5f546042",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PERMNO</th>\n",
       "      <th>date</th>\n",
       "      <th>SHRCD</th>\n",
       "      <th>TICKER</th>\n",
       "      <th>COMNAM</th>\n",
       "      <th>PERMCO</th>\n",
       "      <th>BIDLO</th>\n",
       "      <th>ASKHI</th>\n",
       "      <th>PRC</th>\n",
       "      <th>VOL</th>\n",
       "      <th>RET</th>\n",
       "      <th>BID</th>\n",
       "      <th>ASK</th>\n",
       "      <th>SHROUT</th>\n",
       "      <th>OPENPRC</th>\n",
       "      <th>NUMTRD</th>\n",
       "      <th>sprtrn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10026</td>\n",
       "      <td>2019-08-20</td>\n",
       "      <td>11.0</td>\n",
       "      <td>JJSF</td>\n",
       "      <td>J &amp; J SNACK FOODS CORP</td>\n",
       "      <td>7976</td>\n",
       "      <td>190.9700</td>\n",
       "      <td>196.74001</td>\n",
       "      <td>191.13000</td>\n",
       "      <td>136698.0</td>\n",
       "      <td>-0.020298</td>\n",
       "      <td>191.00000</td>\n",
       "      <td>191.13000</td>\n",
       "      <td>18841.0</td>\n",
       "      <td>194.70000</td>\n",
       "      <td>1903.0</td>\n",
       "      <td>-0.007915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10026</td>\n",
       "      <td>2019-08-21</td>\n",
       "      <td>11.0</td>\n",
       "      <td>JJSF</td>\n",
       "      <td>J &amp; J SNACK FOODS CORP</td>\n",
       "      <td>7976</td>\n",
       "      <td>188.5025</td>\n",
       "      <td>192.56000</td>\n",
       "      <td>189.35001</td>\n",
       "      <td>101583.0</td>\n",
       "      <td>-0.009313</td>\n",
       "      <td>189.17000</td>\n",
       "      <td>189.35001</td>\n",
       "      <td>18841.0</td>\n",
       "      <td>191.98000</td>\n",
       "      <td>2252.0</td>\n",
       "      <td>0.008247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10026</td>\n",
       "      <td>2019-08-22</td>\n",
       "      <td>11.0</td>\n",
       "      <td>JJSF</td>\n",
       "      <td>J &amp; J SNACK FOODS CORP</td>\n",
       "      <td>7976</td>\n",
       "      <td>187.9800</td>\n",
       "      <td>190.39000</td>\n",
       "      <td>189.32001</td>\n",
       "      <td>92198.0</td>\n",
       "      <td>-0.000158</td>\n",
       "      <td>189.32001</td>\n",
       "      <td>189.50000</td>\n",
       "      <td>18841.0</td>\n",
       "      <td>188.89999</td>\n",
       "      <td>1805.0</td>\n",
       "      <td>-0.000506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10026</td>\n",
       "      <td>2019-08-23</td>\n",
       "      <td>11.0</td>\n",
       "      <td>JJSF</td>\n",
       "      <td>J &amp; J SNACK FOODS CORP</td>\n",
       "      <td>7976</td>\n",
       "      <td>185.5900</td>\n",
       "      <td>190.35001</td>\n",
       "      <td>186.14999</td>\n",
       "      <td>75522.0</td>\n",
       "      <td>-0.016744</td>\n",
       "      <td>186.14000</td>\n",
       "      <td>186.28000</td>\n",
       "      <td>18841.0</td>\n",
       "      <td>189.22000</td>\n",
       "      <td>1629.0</td>\n",
       "      <td>-0.025946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10026</td>\n",
       "      <td>2019-08-26</td>\n",
       "      <td>11.0</td>\n",
       "      <td>JJSF</td>\n",
       "      <td>J &amp; J SNACK FOODS CORP</td>\n",
       "      <td>7976</td>\n",
       "      <td>186.7000</td>\n",
       "      <td>191.39999</td>\n",
       "      <td>191.23000</td>\n",
       "      <td>81788.0</td>\n",
       "      <td>0.027290</td>\n",
       "      <td>191.03999</td>\n",
       "      <td>191.25000</td>\n",
       "      <td>18841.0</td>\n",
       "      <td>187.11000</td>\n",
       "      <td>2070.0</td>\n",
       "      <td>0.010983</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PERMNO        date  SHRCD TICKER                  COMNAM  PERMCO     BIDLO  \\\n",
       "0   10026  2019-08-20   11.0   JJSF  J & J SNACK FOODS CORP    7976  190.9700   \n",
       "1   10026  2019-08-21   11.0   JJSF  J & J SNACK FOODS CORP    7976  188.5025   \n",
       "2   10026  2019-08-22   11.0   JJSF  J & J SNACK FOODS CORP    7976  187.9800   \n",
       "3   10026  2019-08-23   11.0   JJSF  J & J SNACK FOODS CORP    7976  185.5900   \n",
       "4   10026  2019-08-26   11.0   JJSF  J & J SNACK FOODS CORP    7976  186.7000   \n",
       "\n",
       "       ASKHI        PRC       VOL        RET        BID        ASK   SHROUT  \\\n",
       "0  196.74001  191.13000  136698.0  -0.020298  191.00000  191.13000  18841.0   \n",
       "1  192.56000  189.35001  101583.0  -0.009313  189.17000  189.35001  18841.0   \n",
       "2  190.39000  189.32001   92198.0  -0.000158  189.32001  189.50000  18841.0   \n",
       "3  190.35001  186.14999   75522.0  -0.016744  186.14000  186.28000  18841.0   \n",
       "4  191.39999  191.23000   81788.0   0.027290  191.03999  191.25000  18841.0   \n",
       "\n",
       "     OPENPRC  NUMTRD    sprtrn  \n",
       "0  194.70000  1903.0 -0.007915  \n",
       "1  191.98000  2252.0  0.008247  \n",
       "2  188.89999  1805.0 -0.000506  \n",
       "3  189.22000  1629.0 -0.025946  \n",
       "4  187.11000  2070.0  0.010983  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock_data_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41d1c952-43d9-4417-9b34-75583787f410",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Convert RET to numeric, coercing errors\n",
    "stock_data_1['RET'] = pd.to_numeric(stock_data_1['RET'], errors='coerce')\n",
    "\n",
    "# Check for any other object types that should be numeric\n",
    "stock_data_1['SHRCD'] = pd.to_numeric(stock_data_1['SHRCD'], errors='coerce')\n",
    "\n",
    "# Step 3: Convert 'date' column to datetime\n",
    "stock_data_1['date'] = pd.to_datetime(stock_data_1['date'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b14ef7c9-265c-4555-8e65-a23ea5e73373",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1938801 entries, 0 to 1938800\n",
      "Data columns (total 17 columns):\n",
      " #   Column   Dtype         \n",
      "---  ------   -----         \n",
      " 0   PERMNO   int64         \n",
      " 1   date     datetime64[ns]\n",
      " 2   SHRCD    float64       \n",
      " 3   TICKER   object        \n",
      " 4   COMNAM   object        \n",
      " 5   PERMCO   int64         \n",
      " 6   BIDLO    float64       \n",
      " 7   ASKHI    float64       \n",
      " 8   PRC      float64       \n",
      " 9   VOL      float64       \n",
      " 10  RET      float64       \n",
      " 11  BID      float64       \n",
      " 12  ASK      float64       \n",
      " 13  SHROUT   float64       \n",
      " 14  OPENPRC  float64       \n",
      " 15  NUMTRD   float64       \n",
      " 16  sprtrn   float64       \n",
      "dtypes: datetime64[ns](1), float64(12), int64(2), object(2)\n",
      "memory usage: 251.5+ MB\n"
     ]
    }
   ],
   "source": [
    "stock_data_1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e205d96-413c-4c39-9291-a536f7887a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with NaN in critical columns (RET, PRC, BID, ASK)\n",
    "stock_data_1_cleaned = stock_data_1.dropna(subset=['RET', 'PRC', 'BID', 'ASK', 'TICKER'])\n",
    "\n",
    "# Drop the NUMTRD column due to excessive missing values\n",
    "stock_data_1_cleaned = stock_data_1_cleaned.drop(columns=['NUMTRD'])\n",
    "\n",
    "# Consider dropping or filling OPENPRC based on its necessity\n",
    "# Example: Drop OPENPRC if not essential\n",
    "stock_data_1_cleaned = stock_data_1_cleaned.drop(columns=['OPENPRC'])\n",
    "\n",
    "# Handle remaining columns with moderate NaN values\n",
    "# Example: Drop rows with missing BIDLO, ASKHI, VOL\n",
    "stock_data_1_cleaned = stock_data_1_cleaned.dropna(subset=['BIDLO', 'ASKHI', 'VOL'])\n",
    "\n",
    "# Optionally fill missing values in columns with very few NaNs, like SHRCD, COMNAM, and SHROUT\n",
    "# For example, filling with the mode or a placeholder value\n",
    "stock_data_1_cleaned['SHRCD'].fillna(stock_data_1_cleaned['SHRCD'].mode()[0], inplace=True)\n",
    "stock_data_1_cleaned['COMNAM'].fillna(\"Unknown\", inplace=True)\n",
    "stock_data_1_cleaned['SHROUT'].fillna(stock_data_1_cleaned['SHROUT'].median(), inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "88c42986-519a-451e-b30b-2b3f987b032d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the cleaned data: (1926738, 15)\n"
     ]
    }
   ],
   "source": [
    "# Check the shape of the cleaned data\n",
    "print(\"Shape of the cleaned data:\", stock_data_1_cleaned.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e21be5d9-de7a-41e7-98a9-bc0da2b3b7bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of NaN values in each column:\n",
      "PERMNO    0\n",
      "date      0\n",
      "SHRCD     0\n",
      "TICKER    0\n",
      "COMNAM    0\n",
      "PERMCO    0\n",
      "BIDLO     0\n",
      "ASKHI     0\n",
      "PRC       0\n",
      "VOL       0\n",
      "RET       0\n",
      "BID       0\n",
      "ASK       0\n",
      "SHROUT    0\n",
      "sprtrn    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "nan_counts_2 = stock_data_1_cleaned.isna().sum()\n",
    "\n",
    "# Display the number of NaN values for each column\n",
    "print(\"Number of NaN values in each column:\")\n",
    "print(nan_counts_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6c242f2d-2fa7-476a-b098-07d802733614",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1926738 entries, 0 to 1938800\n",
      "Data columns (total 15 columns):\n",
      " #   Column  Dtype         \n",
      "---  ------  -----         \n",
      " 0   PERMNO  int64         \n",
      " 1   date    datetime64[ns]\n",
      " 2   SHRCD   float64       \n",
      " 3   TICKER  object        \n",
      " 4   COMNAM  object        \n",
      " 5   PERMCO  int64         \n",
      " 6   BIDLO   float64       \n",
      " 7   ASKHI   float64       \n",
      " 8   PRC     float64       \n",
      " 9   VOL     float64       \n",
      " 10  RET     float64       \n",
      " 11  BID     float64       \n",
      " 12  ASK     float64       \n",
      " 13  SHROUT  float64       \n",
      " 14  sprtrn  float64       \n",
      "dtypes: datetime64[ns](1), float64(10), int64(2), object(2)\n",
      "memory usage: 235.2+ MB\n"
     ]
    }
   ],
   "source": [
    "stock_data_1_cleaned.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "30fce4ee-eac2-4039-9d90-ffec5759234a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PERMNO</th>\n",
       "      <th>date</th>\n",
       "      <th>SHRCD</th>\n",
       "      <th>PERMCO</th>\n",
       "      <th>BIDLO</th>\n",
       "      <th>ASKHI</th>\n",
       "      <th>PRC</th>\n",
       "      <th>VOL</th>\n",
       "      <th>RET</th>\n",
       "      <th>BID</th>\n",
       "      <th>ASK</th>\n",
       "      <th>SHROUT</th>\n",
       "      <th>sprtrn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.926738e+06</td>\n",
       "      <td>1926738</td>\n",
       "      <td>1.926738e+06</td>\n",
       "      <td>1.926738e+06</td>\n",
       "      <td>1.926738e+06</td>\n",
       "      <td>1.926738e+06</td>\n",
       "      <td>1.926738e+06</td>\n",
       "      <td>1.926738e+06</td>\n",
       "      <td>1.926738e+06</td>\n",
       "      <td>1.926738e+06</td>\n",
       "      <td>1.926738e+06</td>\n",
       "      <td>1.926738e+06</td>\n",
       "      <td>1.926738e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.662152e+04</td>\n",
       "      <td>2020-02-19 12:30:49.444605440</td>\n",
       "      <td>3.239542e+01</td>\n",
       "      <td>4.187518e+04</td>\n",
       "      <td>7.859034e+01</td>\n",
       "      <td>8.030824e+01</td>\n",
       "      <td>7.838405e+01</td>\n",
       "      <td>1.240891e+06</td>\n",
       "      <td>8.651649e-04</td>\n",
       "      <td>7.939028e+01</td>\n",
       "      <td>7.955532e+01</td>\n",
       "      <td>9.972811e+04</td>\n",
       "      <td>7.987086e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.002600e+04</td>\n",
       "      <td>2019-08-20 00:00:00</td>\n",
       "      <td>1.100000e+01</td>\n",
       "      <td>5.000000e+00</td>\n",
       "      <td>3.000000e-04</td>\n",
       "      <td>2.600000e-02</td>\n",
       "      <td>-6.525300e+02</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-8.785710e-01</td>\n",
       "      <td>1.000000e-02</td>\n",
       "      <td>2.290000e-02</td>\n",
       "      <td>9.000000e+00</td>\n",
       "      <td>-1.198410e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.597300e+04</td>\n",
       "      <td>2019-11-18 00:00:00</td>\n",
       "      <td>1.100000e+01</td>\n",
       "      <td>3.049200e+04</td>\n",
       "      <td>8.850000e+00</td>\n",
       "      <td>9.300000e+00</td>\n",
       "      <td>8.130000e+00</td>\n",
       "      <td>2.008300e+04</td>\n",
       "      <td>-1.152700e-02</td>\n",
       "      <td>9.030000e+00</td>\n",
       "      <td>9.100000e+00</td>\n",
       "      <td>7.000000e+03</td>\n",
       "      <td>-4.011000e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.900700e+04</td>\n",
       "      <td>2020-02-20 00:00:00</td>\n",
       "      <td>1.200000e+01</td>\n",
       "      <td>5.212700e+04</td>\n",
       "      <td>2.155000e+01</td>\n",
       "      <td>2.216445e+01</td>\n",
       "      <td>2.125000e+01</td>\n",
       "      <td>1.478580e+05</td>\n",
       "      <td>3.360000e-04</td>\n",
       "      <td>2.181000e+01</td>\n",
       "      <td>2.192000e+01</td>\n",
       "      <td>2.747100e+04</td>\n",
       "      <td>1.870000e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8.653600e+04</td>\n",
       "      <td>2020-05-21 00:00:00</td>\n",
       "      <td>7.300000e+01</td>\n",
       "      <td>5.498700e+04</td>\n",
       "      <td>4.246000e+01</td>\n",
       "      <td>4.365990e+01</td>\n",
       "      <td>4.268000e+01</td>\n",
       "      <td>6.986922e+05</td>\n",
       "      <td>1.182300e-02</td>\n",
       "      <td>4.301000e+01</td>\n",
       "      <td>4.311000e+01</td>\n",
       "      <td>7.546800e+04</td>\n",
       "      <td>7.695000e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.343600e+04</td>\n",
       "      <td>2020-08-20 00:00:00</td>\n",
       "      <td>7.500000e+01</td>\n",
       "      <td>5.737000e+04</td>\n",
       "      <td>3.445500e+05</td>\n",
       "      <td>3.474000e+05</td>\n",
       "      <td>3.449700e+05</td>\n",
       "      <td>1.003256e+09</td>\n",
       "      <td>1.025182e+01</td>\n",
       "      <td>3.451400e+05</td>\n",
       "      <td>3.455890e+05</td>\n",
       "      <td>9.308301e+06</td>\n",
       "      <td>9.382800e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.433517e+04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.763045e+01</td>\n",
       "      <td>1.709054e+04</td>\n",
       "      <td>3.485893e+03</td>\n",
       "      <td>3.538367e+03</td>\n",
       "      <td>3.512855e+03</td>\n",
       "      <td>5.868059e+06</td>\n",
       "      <td>5.131279e-02</td>\n",
       "      <td>3.511437e+03</td>\n",
       "      <td>3.516463e+03</td>\n",
       "      <td>3.360675e+05</td>\n",
       "      <td>2.085427e-02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             PERMNO                           date         SHRCD  \\\n",
       "count  1.926738e+06                        1926738  1.926738e+06   \n",
       "mean   4.662152e+04  2020-02-19 12:30:49.444605440  3.239542e+01   \n",
       "min    1.002600e+04            2019-08-20 00:00:00  1.100000e+01   \n",
       "25%    1.597300e+04            2019-11-18 00:00:00  1.100000e+01   \n",
       "50%    1.900700e+04            2020-02-20 00:00:00  1.200000e+01   \n",
       "75%    8.653600e+04            2020-05-21 00:00:00  7.300000e+01   \n",
       "max    9.343600e+04            2020-08-20 00:00:00  7.500000e+01   \n",
       "std    3.433517e+04                            NaN  2.763045e+01   \n",
       "\n",
       "             PERMCO         BIDLO         ASKHI           PRC           VOL  \\\n",
       "count  1.926738e+06  1.926738e+06  1.926738e+06  1.926738e+06  1.926738e+06   \n",
       "mean   4.187518e+04  7.859034e+01  8.030824e+01  7.838405e+01  1.240891e+06   \n",
       "min    5.000000e+00  3.000000e-04  2.600000e-02 -6.525300e+02  0.000000e+00   \n",
       "25%    3.049200e+04  8.850000e+00  9.300000e+00  8.130000e+00  2.008300e+04   \n",
       "50%    5.212700e+04  2.155000e+01  2.216445e+01  2.125000e+01  1.478580e+05   \n",
       "75%    5.498700e+04  4.246000e+01  4.365990e+01  4.268000e+01  6.986922e+05   \n",
       "max    5.737000e+04  3.445500e+05  3.474000e+05  3.449700e+05  1.003256e+09   \n",
       "std    1.709054e+04  3.485893e+03  3.538367e+03  3.512855e+03  5.868059e+06   \n",
       "\n",
       "                RET           BID           ASK        SHROUT        sprtrn  \n",
       "count  1.926738e+06  1.926738e+06  1.926738e+06  1.926738e+06  1.926738e+06  \n",
       "mean   8.651649e-04  7.939028e+01  7.955532e+01  9.972811e+04  7.987086e-04  \n",
       "min   -8.785710e-01  1.000000e-02  2.290000e-02  9.000000e+00 -1.198410e-01  \n",
       "25%   -1.152700e-02  9.030000e+00  9.100000e+00  7.000000e+03 -4.011000e-03  \n",
       "50%    3.360000e-04  2.181000e+01  2.192000e+01  2.747100e+04  1.870000e-03  \n",
       "75%    1.182300e-02  4.301000e+01  4.311000e+01  7.546800e+04  7.695000e-03  \n",
       "max    1.025182e+01  3.451400e+05  3.455890e+05  9.308301e+06  9.382800e-02  \n",
       "std    5.131279e-02  3.511437e+03  3.516463e+03  3.360675e+05  2.085427e-02  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock_data_1_cleaned.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ad27d765-f16a-464b-a40e-d366f3e13ab3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PERMNO  PRC_start  PRC_end  price_increased\n",
      "0   10026     173.59   123.80                0\n",
      "1   10028       2.38     2.60                1\n",
      "2   10032      73.27    43.00                0\n",
      "3   10044       8.48     3.77                0\n",
      "4   10051      23.88    13.00                0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Filter data for the start and end dates\n",
    "start_date = '2020-02-14'\n",
    "end_date = '2020-03-20'\n",
    "\n",
    "# Extract prices at the start and end dates\n",
    "prc_start = stock_data_1_cleaned[stock_data_1_cleaned['date'] == start_date][['PERMNO', 'PRC']].rename(columns={'PRC': 'PRC_start'})\n",
    "prc_end = stock_data_1_cleaned[stock_data_1_cleaned['date'] == end_date][['PERMNO', 'PRC']].rename(columns={'PRC': 'PRC_end'})\n",
    "\n",
    "# Merge start and end prices on PERMNO\n",
    "price_change_df = pd.merge(prc_start, prc_end, on='PERMNO', how='inner')\n",
    "\n",
    "# Create the 'price_increased' column (1 if price increased, otherwise 0)\n",
    "price_change_df['price_increased'] = (price_change_df['PRC_end'] > price_change_df['PRC_start']).astype(int)\n",
    "\n",
    "# Verify the created price_increased column\n",
    "print(price_change_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0c5604c6-e1ec-40f7-8064-90c198f27278",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PERMNO</th>\n",
       "      <th>PRC_start</th>\n",
       "      <th>PRC_end</th>\n",
       "      <th>price_increased</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10026</td>\n",
       "      <td>173.59000</td>\n",
       "      <td>123.80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10028</td>\n",
       "      <td>2.38000</td>\n",
       "      <td>2.60</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10032</td>\n",
       "      <td>73.27000</td>\n",
       "      <td>43.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10044</td>\n",
       "      <td>8.48000</td>\n",
       "      <td>3.77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10051</td>\n",
       "      <td>23.88000</td>\n",
       "      <td>13.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7537</th>\n",
       "      <td>93426</td>\n",
       "      <td>33.77000</td>\n",
       "      <td>17.95</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7538</th>\n",
       "      <td>93427</td>\n",
       "      <td>64.99000</td>\n",
       "      <td>47.78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7539</th>\n",
       "      <td>93429</td>\n",
       "      <td>125.63000</td>\n",
       "      <td>79.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7540</th>\n",
       "      <td>93434</td>\n",
       "      <td>2.27000</td>\n",
       "      <td>2.19</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7541</th>\n",
       "      <td>93436</td>\n",
       "      <td>800.03003</td>\n",
       "      <td>427.53</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7542 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      PERMNO  PRC_start  PRC_end  price_increased\n",
       "0      10026  173.59000   123.80                0\n",
       "1      10028    2.38000     2.60                1\n",
       "2      10032   73.27000    43.00                0\n",
       "3      10044    8.48000     3.77                0\n",
       "4      10051   23.88000    13.00                0\n",
       "...      ...        ...      ...              ...\n",
       "7537   93426   33.77000    17.95                0\n",
       "7538   93427   64.99000    47.78                0\n",
       "7539   93429  125.63000    79.69                0\n",
       "7540   93434    2.27000     2.19                0\n",
       "7541   93436  800.03003   427.53                0\n",
       "\n",
       "[7542 rows x 4 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "price_change_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8ead8240-60db-4e65-a6e8-43e05755c682",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of price increases: 465\n",
      "Total number of records: 7542\n",
      "Percentage of records with price increase: 6.17%\n"
     ]
    }
   ],
   "source": [
    "# Count the number of price increases\n",
    "price_increases = price_change_df['price_increased'].sum()\n",
    "\n",
    "# Count the total number of records\n",
    "total_records = price_change_df['price_increased'].count()\n",
    "\n",
    "# Print the results\n",
    "print(f\"Number of price increases: {price_increases}\")\n",
    "print(f\"Total number of records: {total_records}\")\n",
    "print(f\"Percentage of records with price increase: {price_increases / total_records * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "60bef8b0-8f43-4f54-b839-5eb2c0dc05b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PERMNO       date        PRC  price_increased\n",
      "0   10026 2019-08-20  191.13000              0.0\n",
      "1   10026 2019-08-21  189.35001              0.0\n",
      "2   10026 2019-08-22  189.32001              0.0\n",
      "3   10026 2019-08-23  186.14999              0.0\n",
      "4   10026 2019-08-26  191.23000              0.0\n"
     ]
    }
   ],
   "source": [
    "# Merge the price_change_df with the main dataset to get the price_increased column\n",
    "stock_data_1_cleaned = pd.merge(stock_data_1_cleaned, price_change_df[['PERMNO', 'price_increased']], on='PERMNO', how='left')\n",
    "\n",
    "# Fill NaN values in price_increased with 0 (indicating no price increase)\n",
    "stock_data_1_cleaned['price_increased'].fillna(0, inplace=True)\n",
    "\n",
    "# Verify that the merge and fill are correct\n",
    "print(stock_data_1_cleaned[['PERMNO', 'date', 'PRC', 'price_increased']].dropna().head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "27b42bae-0768-43ef-933a-368ca58a3feb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in 'price_increased': [0. 1.]\n",
      "Number of NaN values in 'price_increased': 0\n",
      "Count of each value in 'price_increased':\n",
      "price_increased\n",
      "0.0    1814803\n",
      "1.0     111935\n",
      "Name: count, dtype: int64\n",
      "   PERMNO       date        PRC  price_increased\n",
      "0   10026 2019-08-20  191.13000              0.0\n",
      "1   10026 2019-08-21  189.35001              0.0\n",
      "2   10026 2019-08-22  189.32001              0.0\n",
      "3   10026 2019-08-23  186.14999              0.0\n",
      "4   10026 2019-08-26  191.23000              0.0\n"
     ]
    }
   ],
   "source": [
    "# Check the unique values in the 'price_increased' column\n",
    "unique_values = stock_data_1_cleaned['price_increased'].unique()\n",
    "print(f\"Unique values in 'price_increased': {unique_values}\")\n",
    "\n",
    "# Ensure there are no NaN values in the 'price_increased' column\n",
    "num_nans = stock_data_1_cleaned['price_increased'].isna().sum()\n",
    "print(f\"Number of NaN values in 'price_increased': {num_nans}\")\n",
    "\n",
    "# Count the number of records for each value (0 or 1) in 'price_increased'\n",
    "value_counts = stock_data_1_cleaned['price_increased'].value_counts()\n",
    "print(\"Count of each value in 'price_increased':\")\n",
    "print(value_counts)\n",
    "\n",
    "# Display the first few rows to visually verify the values in 'price_increased'\n",
    "print(stock_data_1_cleaned[['PERMNO', 'date', 'PRC', 'price_increased']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3f6816a3-8aee-41f3-bdf7-9ad4157cc404",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Select the relevant features\n",
    "features = ['BIDLO', 'ASKHI', 'PRC', 'VOL', 'RET', 'BID', 'ASK', 'SHROUT', 'sprtrn', 'SHRCD']\n",
    "X = stock_data_1_cleaned[features]\n",
    "y = stock_data_1_cleaned['price_increased']\n",
    "\n",
    "# Split the data into training and testing sets (stratify to maintain balance in target variable)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f69e733f-eb9c-4536-9858-59cc50aabf0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Normalize the continuous features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Convert scaled arrays back to DataFrame\n",
    "X_train_scaled = pd.DataFrame(X_train_scaled, columns=features, index=X_train.index)\n",
    "X_test_scaled = pd.DataFrame(X_test_scaled, columns=features, index=X_test.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b94fc3c1-672e-4153-9519-7abb1d232a48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9416916657151458\n",
      "Precision: 0.29901960784313725\n",
      "Recall: 0.0027247956403269754\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      1.00      0.97    362961\n",
      "         1.0       0.30      0.00      0.01     22387\n",
      "\n",
      "    accuracy                           0.94    385348\n",
      "   macro avg       0.62      0.50      0.49    385348\n",
      "weighted avg       0.90      0.94      0.91    385348\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, classification_report\n",
    "\n",
    "# Fit the logistic regression model\n",
    "logreg = LogisticRegression(random_state=42)\n",
    "logreg.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = logreg.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8c9ad256-8289-4d97-b51d-603b5ab7f5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, classification_report\n",
    "\n",
    "def evaluate_model(y_test, y_pred):\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    \n",
    "    print(f'Accuracy: {accuracy}')\n",
    "    print(f'Precision: {precision}')\n",
    "    print(f'Recall: {recall}')\n",
    "    print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3bdda3f8-605a-499d-b165-d6bc1b8674fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression:\n",
      "Accuracy: 0.9416916657151458\n",
      "Precision: 0.29901960784313725\n",
      "Recall: 0.0027247956403269754\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      1.00      0.97    362961\n",
      "         1.0       0.30      0.00      0.01     22387\n",
      "\n",
      "    accuracy                           0.94    385348\n",
      "   macro avg       0.62      0.50      0.49    385348\n",
      "weighted avg       0.90      0.94      0.91    385348\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Logistic Regression with regularization\n",
    "logreg = LogisticRegression(random_state=42, solver='liblinear')\n",
    "logreg.fit(X_train_scaled, y_train)\n",
    "y_pred_logreg = logreg.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the Logistic Regression model\n",
    "print(\"Logistic Regression:\")\n",
    "evaluate_model(y_test, y_pred_logreg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6a824afc-efac-4f9c-a5ac-8fcccaf0859f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, classification_report\n",
    "\n",
    "# Assume 'filtered_data' is your data after processing\n",
    "# Sample 10% of the data\n",
    "sample_data = stock_data_1_cleaned.sample(frac=0.1, random_state=42)\n",
    "\n",
    "# Select features and target\n",
    "features = ['BIDLO', 'ASKHI', 'PRC', 'VOL', 'RET', 'BID', 'ASK', 'SHROUT', 'sprtrn', 'SHRCD']\n",
    "X_sample = sample_data[features]\n",
    "y_sample = sample_data['price_increased']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_sample, y_sample, test_size=0.2, random_state=42, stratify=y_sample)\n",
    "\n",
    "# Normalize the continuous features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Convert scaled arrays back to DataFrame\n",
    "X_train_scaled = pd.DataFrame(X_train_scaled, columns=features, index=X_train.index)\n",
    "X_test_scaled = pd.DataFrame(X_test_scaled, columns=features, index=X_test.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "22d26541-2f87-4d35-9110-de9eea2b05b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, classification_report\n",
    "\n",
    "# Function to evaluate models\n",
    "def evaluate_model(model, X_train, y_train, X_test, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    \n",
    "    print(f'Model: {model.__class__.__name__}')\n",
    "    print(f'Accuracy: {accuracy}')\n",
    "    print(f'Precision: {precision}')\n",
    "    print(f'Recall: {recall}')\n",
    "    print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "    print('-' * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "81e2bcc5-de40-47d4-b641-116d4ade022f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: RandomForestClassifier\n",
      "Accuracy: 0.956455170624108\n",
      "Precision: 0.8404384896467723\n",
      "Recall: 0.30844881537773805\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      1.00      0.98     36298\n",
      "         1.0       0.84      0.31      0.45      2237\n",
      "\n",
      "    accuracy                           0.96     38535\n",
      "   macro avg       0.90      0.65      0.71     38535\n",
      "weighted avg       0.95      0.96      0.95     38535\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Run Random Forest Classifier\n",
    "rf = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "evaluate_model(rf, X_train_scaled, y_train, X_test_scaled, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2ce821cf-a62c-4f7f-93ce-c07608904b12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: GradientBoostingClassifier\n",
      "Accuracy: 0.9451926819774231\n",
      "Precision: 0.6971608832807571\n",
      "Recall: 0.09879302637460885\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      1.00      0.97     36298\n",
      "         1.0       0.70      0.10      0.17      2237\n",
      "\n",
      "    accuracy                           0.95     38535\n",
      "   macro avg       0.82      0.55      0.57     38535\n",
      "weighted avg       0.93      0.95      0.93     38535\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Run Gradient Boosting Classifier\n",
    "gb = GradientBoostingClassifier(random_state=42)\n",
    "evaluate_model(gb, X_train_scaled, y_train, X_test_scaled, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "74d4909a-4813-4b07-a497-e5528462d101",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: KNeighborsClassifier\n",
      "Accuracy: 0.9405475541715324\n",
      "Precision: 0.43601895734597157\n",
      "Recall: 0.08225301743406348\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.99      0.97     36298\n",
      "         1.0       0.44      0.08      0.14      2237\n",
      "\n",
      "    accuracy                           0.94     38535\n",
      "   macro avg       0.69      0.54      0.55     38535\n",
      "weighted avg       0.92      0.94      0.92     38535\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Run K-Nearest Neighbors\n",
    "knn = KNeighborsClassifier(n_jobs=-1)\n",
    "evaluate_model(knn, X_train_scaled, y_train, X_test_scaled, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c3808ac3-4b32-4e67-9932-c35cea4c0d44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: SVC\n",
      "Accuracy: 0.1444401193719995\n",
      "Precision: 0.058219768845954804\n",
      "Recall: 0.9052302190433617\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.10      0.18     36298\n",
      "         1.0       0.06      0.91      0.11      2237\n",
      "\n",
      "    accuracy                           0.14     38535\n",
      "   macro avg       0.50      0.50      0.14     38535\n",
      "weighted avg       0.89      0.14      0.17     38535\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# SVM with linear kernel and limited iterations\n",
    "svm = SVC(kernel='linear', max_iter=1000, random_state=42)\n",
    "evaluate_model(svm, X_train_scaled, y_train, X_test_scaled, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cfc81ca9-7e3f-4acc-8e1c-7dac95c3b72b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "\n",
    "# Assume you have your filtered_data ready from previous steps\n",
    "\n",
    "# Use a smaller sample of data for quick testing\n",
    "sampled_data = stock_data_1_cleaned.sample(n=10000, random_state=42)\n",
    "\n",
    "# Split the sample data into features and target\n",
    "X_sample = sampled_data[features]\n",
    "y_sample = sampled_data['price_increased']\n",
    "\n",
    "# Split into training and testing sets\n",
    "X_train_sample, X_test_sample, y_train_sample, y_test_sample = train_test_split(X_sample, y_sample, test_size=0.2, random_state=42, stratify=y_sample)\n",
    "\n",
    "# Normalize the continuous features\n",
    "scaler = StandardScaler()\n",
    "X_train_sample_scaled = scaler.fit_transform(X_train_sample)\n",
    "X_test_sample_scaled = scaler.transform(X_test_sample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "218acbe7-861e-4956-bbc9-a0ca299b3444",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble Voting Classifier with Class Weights - Accuracy: 0.9475\n",
      "Ensemble Voting Classifier with Class Weights - Precision: 0.5\n",
      "Ensemble Voting Classifier with Class Weights - Recall: 0.06666666666666667\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      1.00      0.97      1895\n",
      "         1.0       0.50      0.07      0.12       105\n",
      "\n",
      "    accuracy                           0.95      2000\n",
      "   macro avg       0.73      0.53      0.55      2000\n",
      "weighted avg       0.93      0.95      0.93      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Update the models to include class weights\n",
    "logreg = LogisticRegression(random_state=42, class_weight='balanced')\n",
    "rf = RandomForestClassifier(random_state=42, class_weight='balanced')\n",
    "knn = KNeighborsClassifier()  # KNN does not have class weights\n",
    "svc = SVC(probability=True, random_state=42, class_weight='balanced')\n",
    "\n",
    "# Create a Voting Classifier with soft voting and class-weighted models\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[('lr', logreg), ('rf', rf), ('knn', knn), ('svc', svc)],\n",
    "    voting='soft'\n",
    ")\n",
    "\n",
    "# Fit the Voting Classifier on the training data\n",
    "voting_clf.fit(X_train_sample_scaled, y_train_sample)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_voting = voting_clf.predict(X_test_sample_scaled)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test_sample, y_pred_voting)\n",
    "precision = precision_score(y_test_sample, y_pred_voting)\n",
    "recall = recall_score(y_test_sample, y_pred_voting)\n",
    "\n",
    "print(f'Ensemble Voting Classifier with Class Weights - Accuracy: {accuracy}')\n",
    "print(f'Ensemble Voting Classifier with Class Weights - Precision: {precision}')\n",
    "print(f'Ensemble Voting Classifier with Class Weights - Recall: {recall}')\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test_sample, y_pred_voting))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1f4b2459-b0b7-4700-81c8-8e8e42ce9a39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble Voting Classifier with SMOTE - Accuracy: 0.838\n",
      "Ensemble Voting Classifier with SMOTE - Precision: 0.15457413249211358\n",
      "Ensemble Voting Classifier with SMOTE - Recall: 0.4666666666666667\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.86      0.91      1895\n",
      "         1.0       0.15      0.47      0.23       105\n",
      "\n",
      "    accuracy                           0.84      2000\n",
      "   macro avg       0.56      0.66      0.57      2000\n",
      "weighted avg       0.92      0.84      0.87      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Apply SMOTE to the training data\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_sample_resampled, y_train_sample_resampled = smote.fit_resample(X_train_sample_scaled, y_train_sample)\n",
    "\n",
    "# Fit the Voting Classifier on the resampled training data\n",
    "voting_clf.fit(X_train_sample_resampled, y_train_sample_resampled)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_voting = voting_clf.predict(X_test_sample_scaled)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test_sample, y_pred_voting)\n",
    "precision = precision_score(y_test_sample, y_pred_voting)\n",
    "recall = recall_score(y_test_sample, y_pred_voting)\n",
    "\n",
    "print(f'Ensemble Voting Classifier with SMOTE - Accuracy: {accuracy}')\n",
    "print(f'Ensemble Voting Classifier with SMOTE - Precision: {precision}')\n",
    "print(f'Ensemble Voting Classifier with SMOTE - Recall: {recall}')\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test_sample, y_pred_voting))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "82fdfd62-c24d-4635-afd1-da1ccf611979",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                  Model  Accuracy  Precision  Recall\n",
      "0                   Logistic Regression    0.9417     0.2990  0.0027\n",
      "1                         Random Forest    0.9565     0.8404  0.3084\n",
      "2                     Gradient Boosting    0.9454     0.6863  0.1121\n",
      "3                   K-Nearest Neighbors    0.9405     0.4360  0.0823\n",
      "4                Support Vector Machine    0.1444     0.0582  0.9052\n",
      "5                     Voting Classifier    0.9475     0.5000  0.0667\n",
      "6  Voting Classifier with Class Weights    0.9475     0.5000  0.0667\n",
      "7          Voting Classifier with SMOTE    0.8380     0.1546  0.4667\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a DataFrame to store the metrics\n",
    "model_metrics = pd.DataFrame({\n",
    "    'Model': [\n",
    "        'Logistic Regression', \n",
    "        'Random Forest', \n",
    "        'Gradient Boosting', \n",
    "        'K-Nearest Neighbors', \n",
    "        'Support Vector Machine',\n",
    "        'Voting Classifier',\n",
    "        'Voting Classifier with Class Weights',\n",
    "        'Voting Classifier with SMOTE'\n",
    "    ],\n",
    "    'Accuracy': [\n",
    "        0.9417,  # Logistic Regression\n",
    "        0.9565,  # Random Forest\n",
    "        0.9454,  # Gradient Boosting\n",
    "        0.9405,  # K-Nearest Neighbors\n",
    "        0.1444,  # Support Vector Machine\n",
    "        0.9475,  # Voting Classifier\n",
    "        0.9475,  # Voting Classifier with Class Weights\n",
    "        0.8380   # Voting Classifier with SMOTE\n",
    "    ],\n",
    "    'Precision': [\n",
    "        0.2990,  # Logistic Regression\n",
    "        0.8404,  # Random Forest\n",
    "        0.6863,  # Gradient Boosting\n",
    "        0.4360,  # K-Nearest Neighbors\n",
    "        0.0582,  # Support Vector Machine\n",
    "        0.5000,  # Voting Classifier\n",
    "        0.5000,  # Voting Classifier with Class Weights\n",
    "        0.1546   # Voting Classifier with SMOTE\n",
    "    ],\n",
    "    'Recall': [\n",
    "        0.0027,  # Logistic Regression\n",
    "        0.3084,  # Random Forest\n",
    "        0.1121,  # Gradient Boosting\n",
    "        0.0823,  # K-Nearest Neighbors\n",
    "        0.9052,  # Support Vector Machine\n",
    "        0.0667,  # Voting Classifier\n",
    "        0.0667,  # Voting Classifier with Class Weights\n",
    "        0.4667   # Voting Classifier with SMOTE\n",
    "    ]\n",
    "})\n",
    "\n",
    "# Display the table\n",
    "print(model_metrics)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
